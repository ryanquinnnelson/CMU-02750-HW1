{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2. IWAL algorithm implementation (50 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this question is to implement Importance Weighted Active Learning (IWAL) algorithm. For this question, you will not use modAL, but instead will implement IWAL routine from scratch using scikit-learn, NumPy and native Python. \n",
    "\n",
    "In this question, we will use a simple synthetic dataset for a binary classification problem. Each data point has only 2 features. The dataset is provided in 2 files -- “data_iwal.npy”, which contains features and “labels_iwal.npy”, which contains labels. \n",
    "\n",
    "For simplicity, you will implement bootstrapping rejection sampling subroutine with logistic regression and hinge loss.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "𝐂𝐨𝐦𝐩𝐥𝐞𝐭𝐞 𝐭𝐡𝐞 𝐜𝐨𝐝𝐞 𝐮𝐧𝐝𝐞𝐫 ###𝐓𝐎 𝐃𝐎 𝐢𝐧 𝐞𝐚𝐜𝐡 𝐜𝐞𝐥𝐥 𝐚𝐧𝐝 𝐩𝐫𝐨𝐝𝐮𝐜𝐞 𝐭𝐡𝐞 𝐫𝐞𝐪𝐮𝐢𝐫𝐞𝐝 𝐩𝐥𝐨𝐭𝐬.  Feel free to define any helper functions as you see fit. You may import and use any modules in scikit-learn and NumPy to help with your implementations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we import necessary modules. Feel free to add something else here if you need it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import hinge_loss, log_loss\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# import my module\n",
    "import iwal.iwal_functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we read the data and split it into train and test datasets. Train will be used to train our classification model and test will be used to validate the performance, monitor overfitting and compare the results of the model trained with Active Learning with the ones of the model trained from scratch. We set aside 1/3 of the dataset for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load(\"data/q2/data_iwal.npy\")\n",
    "y = np.load(\"data/q2/labels_iwal.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(134, 2)\n",
      "(134,)\n",
      "(66, 2)\n",
      "(66,)\n",
      "[2.59193175 1.14706863]\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "print(X[0])\n",
    "print(y[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2.1\n",
    "Type your answers for the theoretical questions below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. What is the idea behind IWAL algorithm?\n",
    "\n",
    "**Your answer goes here**\n",
    "\n",
    "2. What are the assumptions made for the IWAL algorithm?\n",
    "\n",
    "**Your answer goes here**\n",
    "\n",
    "3. What are the pros and cons of IWAL algorithm?\n",
    "\n",
    "**Your answer goes here**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2.2 Implement IWAL algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part you will implement a functiom that performs a single query of Algorithm 1 IWAL (subroutine rejection-sampling) from the paper. Below is the function description that you can follow in your implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[1]\n",
      "[1, 2]\n"
     ]
    }
   ],
   "source": [
    "test = dict()\n",
    "test['X'] = []\n",
    "print(test['X'])\n",
    "test['X'].append(1)\n",
    "print(test['X'])\n",
    "test['X'].append(2)\n",
    "print(test['X'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history = {\n",
    "        'X': [],\n",
    "        'y': [],\n",
    "        'p': [],\n",
    "        'Q': []\n",
    "    }\n",
    "'X' in history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Equations\n",
    "\n",
    "$h_t = \\underset{h \\in H}{argmin}\\sum_{(x,y,c)\\in S_t}c \\cdot l(h(x),y)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#?? seems wrong\n",
    "#?? how to define learning process? do I simply use .fit()?\n",
    "#?? SVM for hinge loss?\n",
    "def get_h_min(H, S):\n",
    "    '''\n",
    "    Derives the optimal model from model class H using given set S\n",
    "    of data points selected for labeling.\n",
    "    \n",
    "    Args:\n",
    "        H: hypothesis space\n",
    "        \n",
    "        S: Set representing samples chosen for labeling, where each\n",
    "        element in the set is a tuple {x,y,c}. c is 1/p, where p is\n",
    "        the rejection threshold probability for this sample.\n",
    "        \n",
    "    Returns:\n",
    "        h_t: object of scikit-learn model class H, that is optimal \n",
    "        at current time step.\n",
    "    '''\n",
    "    min_h = None\n",
    "    min_sum = 1\n",
    "    \n",
    "    # get X,y,c from S\n",
    "    \n",
    "    for h in H:\n",
    "        # calculate log loss\n",
    "        y_predict = h.predict(X)\n",
    "        loss = log_loss(y,y_predict)\n",
    "\n",
    "        # multiple loss cells by c\n",
    "        result = np.multiply(c,loss)\n",
    "        \n",
    "        # sum\n",
    "        curr_sum = np.sum(result)\n",
    "        \n",
    "        if curr_sum < min_sum:\n",
    "            min_h = h\n",
    "            min_sum = curr_sum\n",
    "    \n",
    "    return min_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO: Implement Algorithm 1 from the paper\n",
    "#?? S vs history\n",
    "#?? how to choose Q_t? use Bernoulli distribution?\n",
    "#?? no y_t in parameters\n",
    "#?? no S in parameters\n",
    "#?? where is H defined? hypothesis space\n",
    "#?? H is not list of models?\n",
    "from scipy.stats import bernoulli\n",
    "\n",
    "\n",
    "def IWAL_query(x_t, y_t, S, rejection_threshold, history, H, **kwargs):\n",
    "    '''\n",
    "    This function implements a single query IWAL algorithm from the \n",
    "    paper by Beygelzimer et al https://arxiv.org/pdf/0812.4952.pdf\n",
    "    \n",
    "    Args:\n",
    "        x_t: currently considered sample.\n",
    "        \n",
    "        y_t: label for x, will be added to history if requested.\n",
    "        \n",
    "        S: Set representing samples chosen for labeling, where each\n",
    "        element in the set is a tuple {x,y,c}. c is 1/p, where p is\n",
    "        the rejection threshold probability for this sample.\n",
    "        \n",
    "        rejection_threshold: python function, accepts current data \n",
    "        point x_t and some arbitrary arguments and returns \n",
    "        probability of requesting a label for x_t.\n",
    "        \n",
    "        history: Dictionary of query history. history.keys() will\n",
    "        return dict_keys(['X', 'y', 'p', 'Q']), where the value of \n",
    "        each key is a list containing the following:\n",
    "            X -- sampled data points\n",
    "            y -- labels matching to data points\n",
    "            p -- rejection probabilities matching to data points\n",
    "            Q -- coin flips matching to data points\n",
    "        \n",
    "        H: scikit-learn model class, such as \n",
    "        sklearn.linear_model.LogisticRegression, etc.\n",
    "        \n",
    "        **kwargs: dictionary of arbitrary arguments that may be \n",
    "        required by rejection_threshold().\n",
    "   \n",
    "    Returns: \n",
    "        h_t: object of scikit-learn model class H that is optimal \n",
    "        at current time step.\n",
    "    '''\n",
    "    # derive probability of requesting label for x_t\n",
    "    p_t = rejection_threshold(x_t, history)\n",
    "    \n",
    "    # flip a coin using derived probability\n",
    "    Q_t = bernoulli.rvs(p_t)\n",
    "    \n",
    "    # record history\n",
    "    \n",
    "    \n",
    "    # choose actions based on flip\n",
    "    if Q_t == 1: # label is requested\n",
    "        c_t = 1/p_t\n",
    "        S.add((x_t,y_t,c_t)) # add to set s\n",
    "    \n",
    "    # select model with least loss   \n",
    "    h_t = get_h_min(H, S)\n",
    "    \n",
    "    return h_t\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2.3 Implement bootstrapping rejection sampling subroutine\n",
    "In this part you will implement bootstrapping rejection sampling subroutine from the paper, section 7.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Equation\n",
    "$p_t = p_{min}+(1-p_{min})[\\underset{y;h_i,h_j \\in H}{max}L(h_i(x),y)-L(h_j(x),y)]$\n",
    "\n",
    "where $p_{min}$ is a lower bound on the sampling probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_difference(y_true, y_pred_i, y_pred_j, labels, loss):\n",
    "    '''\n",
    "    Calculates the difference in loss.\n",
    "    '''\n",
    "    loss_i = loss(y_true, y_pred_i,labels=labels)\n",
    "    loss_j = loss(y_true, y_pred_j,labels=labels)\n",
    "    return loss_i - loss_j \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss_difference()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('test loss_difference()')\n",
    "test_y_true = np.asarray([0])\n",
    "test_y_pred_i = np.asarray([0])\n",
    "test_y_pred_j = np.asarray([0])\n",
    "loss_difference(test_y_true, test_y_pred_i,test_y_pred_j,[0,1],hinge_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "#?? don't use loss parameter\n",
    "def bootstrap(x, H, labels, loss, p_min=0.1):\n",
    "    '''\n",
    "    This function implements bootstrap rejection threshold \n",
    "    subroutine.\n",
    "    \n",
    "    Args:\n",
    "        x: array-like object of features for currently considered \n",
    "        sample.\n",
    "        \n",
    "        H: list of hypothesis (scikit-learn objects) that are used \n",
    "        in voting.\n",
    "        \n",
    "        labels: list of possible labels for the problem. If binary \n",
    "        classification, labels=[0, 1].\n",
    "        \n",
    "        loss: python function, accepts (y_true,y_pred) and returns\n",
    "        loss of prediction.\n",
    "        \n",
    "        p_min: minimum threshold for the probability.\n",
    "        \n",
    "    Returns:\n",
    "        p_t: probability of requesting the label for x, which is \n",
    "        equal to:\n",
    "            p_min + (1 - p_min)(max_{y, h_i, h_j} L(h_i(x), y) - L(h_j(x), y))\n",
    "    '''\n",
    "    max_value = -10000\n",
    "    \n",
    "    for i in range(len(H)):\n",
    "        for j in range(len(H)):\n",
    "            for label in labels:\n",
    "                \n",
    "                # calculate loss difference between models\n",
    "                y_true = np.full(shape=len(x),fill_value=label,dtype=np.int)\n",
    "                y_pred_i = H[i].predict(x)\n",
    "                y_pred_j = H[j].predict(x)\n",
    "                \n",
    "                curr = loss_difference(y_true, y_pred_i, y_pred_j, labels, loss)\n",
    "                \n",
    "                # update max\n",
    "                if curr > max_value:\n",
    "                    max_value = curr\n",
    "                         \n",
    "    return p_min + (1 - p_min) * max_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('test bootstrap()')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2.4 Organize all implemented parts into a single pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you implemented all part of IWAL algorithm with bootstrap rejection sampling and can organize it into a pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = {}\n",
    "losses = []\n",
    "n_initial = 10\n",
    "n_h = 10\n",
    "\n",
    "X_training, y_training = X_train[:n_initial], y_train[:n_initial]\n",
    "\n",
    "#Initialization: initialize history and H\n",
    "## TODO: your code here\n",
    "\n",
    "# Create n_h classifiers and train them on bootstrapped data (data is sampled with replacement)\n",
    "## TODO: your code goes here\n",
    "    \n",
    "# Perform queries and record loss\n",
    "n_query = 50\n",
    "for t in n_query:\n",
    "    ### TODO: your code goes here\n",
    "    log_loss(y_test, h_t.predict_proba(X_test)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2.5 Compare results of Active Learning vs No Active Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part you need to create object of the same scikit learning class and train it on randomly selected subset of data points and compare results of 2 classifiers. Comment on your observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare to no Active Learning setting\n",
    "\n",
    "## TODO: your code goes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
